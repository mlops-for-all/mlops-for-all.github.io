---
title : "What is MLOps?"
description: "Introduction to MLOps"
lead: ""
draft: false
weight: 101
contributors: ["Jongseob Jeon"]
menu:
  docs:
    parent: "introduction"
---

### 서론

최근, 많은 곳에서 MLOps의 필요성에 대해서 말하고 있습니다. MLOps란 무엇이며 이를 위해서 우리는 무엇을 공부해야 할까요?
저희 *모두의 MLOps*팀은 MLOps에 대해서 공부하려고 하지만 어떻게 시작해야 하는지 모르는 분들을 위한 지침서를 작성하고자 이 프로젝트를 시작하였습니다.
MLOps는 Machine Learning Operations의 약어입니다. 이 중 Operations라는 단어는 도메인과 상황에 따라서 필요로 하는 것이 달라진다는 뜻을 내포하고 있습니다.
특히 집필을 하는 2021년 기준으로 아직 표준이라고 불릴 수 있는 툴이 존재하지 않습니다.
그렇기 때문에 저희가 제시하는 방법을 실제 업무에 바로 적용하기에는 힘들 수도 있습니다.
그럼에도 이 글을 통해서 많은 분들이 MLOps란 무엇이며 각자의 환경에 맞게 어떤 것이 필요한 지를 알 수 있는 첫 디딤돌이 되었으면 합니다.

### Machine Learning Project

2012년 Alexnet 이후 CV, NLP, Tabular Data등 데이터가 존재하는 곳에는 머신러닝과 딥러닝을 적용하고자 하였습니다. 또한 많은 매체에서 AI의 필요성을 외치며 머신러닝과 딥러닝을 이용한 수 많은 프로젝트를 진행하였습니다.
그리고 어떻게 되었을까요? 엘리먼트 AI의 음병찬 동북아 지역 총괄책임자는“10개 기업에 AI 프로젝트를 시작한다면 그 중 9개는 컨셉검증(POC)만 하다 끝난다”고 말했습니다.

이처럼 많은 프로젝트에서 머신러닝과 딥러닝은 이 문제를 풀 수 있을 것 같다는 가능성만을 보여주고 사라졌습니다. 그리고 이 시기 즈음에 맞추어서 AI에게 다시 겨울이 다가오고 있다는 전망들도 나오기 시작했습니다.

왜 거의 모든 프로젝트가 POC 단계에서 끝났을 까요? 이는 머신러닝의 deploy를 가정하지 않았기 때문입니다. 실제 서비스 단계에서 머신러닝과 딥러닝은 생각보다 작은 부분만을 차지합니다. 즉, 실제 서비스로 이어지기 위해서는 단순히 모델만이 아니라 다른 많은 부분을 고려해야 합니다.
구글은 이런 문제를 2015년 Hidden Technical Debt in Machine Learning Systems라는 논문에서 지적한 바 있습니다. 하지만 이 논문이 나올 때는 아직 많은 머신러닝 엔지니어들이 딥러닝과 머신러닝의 가능성을 입증하기 바쁜 시기였기 때문에, 그 중요성에 많은 주의를 기울이지는 않았습니다.

몇 년이 지난 후 머신러닝과 딥러닝 프로젝트들은 자신의 가능성을 입증을 해냈고 이제 실제 서비스에 적용하고자 했습니다. 그리고 많은 사람들이 실제 서비스는 쉽지 않다는 것을 깨달았습니다.

### 기존 시스템의 한계

사람들은 우선 머신러닝과 딥러닝을 기존의 서비스와 같이 바라보고 기존의 서비스에 이를 편입하고자 했습니다.
기존의 서비스에 편입되고 문제가 없었다면 모두가 행복하게 이야기가 마무리 되겠지만 여러 문제들이 발생했습니다.

예를 들어, Data Shift와 같이 기존에 학습된 데이터와 다른 데이터가 들어왔을 때 모델의 성능이 감소하는 현상이 생겼습니다.
기존 서비스에서는 문제가 발생할 경우 엔지니어가 문제의 원인을 진단하고 이를 해결한 후 다시 배포를 하였습니다.
기존의 관행에 따라 머신러닝 엔지니어 혹은 데이터 사이언티스트들은 모델 성능 하락의 원인을 찾고 이를 개선하는 새로운 모델을 배포했습니다.
대부분의 경우 최신의 데이터로 모델을 재학습하는 것만으로도 모델의 성능의 하락을 막을 수 있었기 때문에, 머신러닝 엔지니어들은 주기적으로 모델을 재학습해서 배포하였습니다.

그리고 머신러닝과 딥러닝의 빠른 발전에서 비롯된 문제도 있습니다.
자고 일어나면 새로운 논문이 SOTA(State-of-the-Art)가 되고, 많은 사람들이 사용하는 패키지들은 버전이 매우 빠르게 올라갔습니다.
가장 대표적인 딥러닝 프레임워크인 PyTorch는 약 한 달에서 두 달 사이의 주기로 마이너 버전이 올라갔습니다.
이는 패키지들간의 의존성 문제를 만들었습니다. 새로운 SOTA를 적용하기 위해서 패키지들의 버전을 올리면 과거에 만든 모델이 호환되지 않는 경우도 있었습니다.
이 때부터 머신러닝 엔지니어와 소프트웨어 엔지니어들의 불화가 시작되었습니다.
(예시)

머신러닝 엔지니어와 소프트웨어 엔지니어들은 '모델'을 이용해 서로 소통했습니다. 보통의 경우 머신러닝 엔지니어가 직접 쿼리를 이용해 DB에서 데이터를 다운로드 받고 모델을 학습 후 학습된 모델(Network 구조와 Weights 가 담긴 .h5 혹은 .pkl 파일) 또는 학습하는데 사용했던 소스코드를 소프트웨어 엔지니어에게 전달하였습니다. 그러면 소프트웨어 엔지니어는 전달받은 모델을 모델을 load 한 뒤, 정해진 inference 함수를 감싼 API Server 를 만들어 배포하였습니다.

소프트웨어 엔지니어는 머신러닝 엔지니어에게 정해진 버전의 패키지와 정해진 함수로 구현할 것을 요청합니다.
이제 서로 불만이 쌓이기 시작합니다.
머신러닝 엔지니어는 원하는 버전의 패키지를 사용할 수 없고 소프트웨어 엔지니어는 계속해서 최신 버전으로 환경을 올려달라는 요청이 overload가 되기 시작합니다.

MLOps는 이러한 문제들을 해결하기 위한 방안으로 나오게 되었습니다.

### **Before MLOps**

그럼 MLOps가 도입되기 전에는 어떻게 머신러닝이 실제 서비스에 적용했는지 알아보겠습니다.

<img src="/images/docs/introduction/before-mlops.png" title="before-mlops"/>

MLOps가 도입되기 전 머신러닝이 실제 서빙에서 사용되기 위해서는 위와 같은 workflow를 그렸습니다.

이 때 머신러닝 모델을 배포하기 위해서는 머신러닝 엔지니어가 직접 모델을 학습한 후 모델의 Weight 또는 모델이 저장되어 있는 파일들을 배포를 담당하는 소프트웨어 엔지니어에게 전송하였습니다. 즉, 이 때의 두 직군간의 소통의 주체는 '학습된 모델'이였습니다.

소프트웨어 엔지니어와 머신러닝 엔지니어는 서로 어떤 환경에서 작업을 하는지 알지 못합니다. 보통 소프트웨어 엔지니어는 train, predict(inference) 역할을 하는 함수의 이름과 argument 를 서로 구두로 약속을 통해 지정하거나, 이런 abstract method 를 가진 abtract class 를 상속하여 모델 개발을 하도록 약속한다. 머신러닝 엔지니어는 소프트웨어 엔지니어가 정해준 방식에 맞는 방식에 맞춰서 모델을 생성합니다. 이 경우 문제가 발생했을 때 디버깅의 어려움을 야기합니다. 만약 모델이 처리할 수 없는 입력이 들어올 경우(예를 들어서 `inf`를 야기할 수 있는 값 등) 원인을 파악하는 데 오랜 시간이 소요될 수 있습니다.

### **파이프라인의 도입**

<img src="/images/docs/introduction/after-mlops.png" title="after-mlops"/>

이제 소통의 주체를 '학습된 모델'에서 '파이프라인'으로 옮겨집니다. '파이프라인' 이란 '워크플로우'와 같은 역할을 합니다. 머신러닝 엔지니어는 데이터를 다운로드 받고, 전처리를 수행하며, 모델을 생성하는 과정을 수행하는 파이프라인을 작성하고 이를 소프트웨어 엔지니어에게 전달합니다. 소프트웨어 엔지니어는 전달받은 파이프라인에서 생성되는 모델을 배포합니다. 머신러닝 엔지니어와 소프트웨어 엔지니어는 같은 파이프라인을 사용하기 때문에 모델의 재현, 환경의 변화에 영향을 받지 않게 됩니다. 또한 모델의 문제가 발생했을 때 빠른 디버깅도 가능해집니다.
