"use strict";(self.webpackChunkv_2=self.webpackChunkv_2||[]).push([[204],{3905:(n,e,a)=>{a.d(e,{Zo:()=>d,kt:()=>c});var t=a(7294);function r(n,e,a){return e in n?Object.defineProperty(n,e,{value:a,enumerable:!0,configurable:!0,writable:!0}):n[e]=a,n}function l(n,e){var a=Object.keys(n);if(Object.getOwnPropertySymbols){var t=Object.getOwnPropertySymbols(n);e&&(t=t.filter((function(e){return Object.getOwnPropertyDescriptor(n,e).enumerable}))),a.push.apply(a,t)}return a}function i(n){for(var e=1;e<arguments.length;e++){var a=null!=arguments[e]?arguments[e]:{};e%2?l(Object(a),!0).forEach((function(e){r(n,e,a[e])})):Object.getOwnPropertyDescriptors?Object.defineProperties(n,Object.getOwnPropertyDescriptors(a)):l(Object(a)).forEach((function(e){Object.defineProperty(n,e,Object.getOwnPropertyDescriptor(a,e))}))}return n}function p(n,e){if(null==n)return{};var a,t,r=function(n,e){if(null==n)return{};var a,t,r={},l=Object.keys(n);for(t=0;t<l.length;t++)a=l[t],e.indexOf(a)>=0||(r[a]=n[a]);return r}(n,e);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(n);for(t=0;t<l.length;t++)a=l[t],e.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(n,a)&&(r[a]=n[a])}return r}var o=t.createContext({}),s=function(n){var e=t.useContext(o),a=e;return n&&(a="function"==typeof n?n(e):i(i({},e),n)),a},d=function(n){var e=s(n.components);return t.createElement(o.Provider,{value:e},n.children)},m="mdxType",_={inlineCode:"code",wrapper:function(n){var e=n.children;return t.createElement(t.Fragment,{},e)}},u=t.forwardRef((function(n,e){var a=n.components,r=n.mdxType,l=n.originalType,o=n.parentName,d=p(n,["components","mdxType","originalType","parentName"]),m=s(a),u=r,c=m["".concat(o,".").concat(u)]||m[u]||_[u]||l;return a?t.createElement(c,i(i({ref:e},d),{},{components:a})):t.createElement(c,i({ref:e},d))}));function c(n,e){var a=arguments,r=e&&e.mdxType;if("string"==typeof n||r){var l=a.length,i=new Array(l);i[0]=u;var p={};for(var o in e)hasOwnProperty.call(e,o)&&(p[o]=e[o]);p.originalType=n,p[m]="string"==typeof n?n:r,i[1]=p;for(var s=2;s<l;s++)i[s]=a[s];return t.createElement.apply(null,i)}return t.createElement.apply(null,a)}u.displayName="MDXCreateElement"},3621:(n,e,a)=>{a.r(e),a.d(e,{assets:()=>o,contentTitle:()=>i,default:()=>_,frontMatter:()=>l,metadata:()=>p,toc:()=>s});var t=a(7462),r=(a(7294),a(3905));const l={title:"12. Component - MLFlow",description:"",sidebar_position:12,date:new Date("2021-12-13T00:00:00.000Z"),lastmod:new Date("2021-12-20T00:00:00.000Z"),contributors:["Jongseob Jeon","SeungTae Kim"]},i=void 0,p={unversionedId:"kubeflow/advanced-mlflow",id:"version-1.0/kubeflow/advanced-mlflow",title:"12. Component - MLFlow",description:"",source:"@site/versioned_docs/version-1.0/kubeflow/advanced-mlflow.md",sourceDirName:"kubeflow",slug:"/kubeflow/advanced-mlflow",permalink:"/docs/1.0/kubeflow/advanced-mlflow",draft:!1,editUrl:"https://github.com/mlops-for-all/mlops-for-all.github.io/tree/main/versioned_docs/version-1.0/kubeflow/advanced-mlflow.md",tags:[],version:"1.0",lastUpdatedBy:"conqrean",lastUpdatedAt:1705274857,formattedLastUpdatedAt:"2024\ub144 1\uc6d4 14\uc77c",sidebarPosition:12,frontMatter:{title:"12. Component - MLFlow",description:"",sidebar_position:12,date:"2021-12-13T00:00:00.000Z",lastmod:"2021-12-20T00:00:00.000Z",contributors:["Jongseob Jeon","SeungTae Kim"]},sidebar:"tutorialSidebar",previous:{title:"11. Pipeline - Run Result",permalink:"/docs/1.0/kubeflow/advanced-run"},next:{title:"13. Component - Debugging",permalink:"/docs/1.0/kubeflow/how-to-debug"}},o={},s=[{value:"MLFlow Component",id:"mlflow-component",level:2},{value:"MLFlow in Local",id:"mlflow-in-local",level:2},{value:"1. \ubaa8\ub378 \ud559\uc2b5",id:"1-\ubaa8\ub378-\ud559\uc2b5",level:3},{value:"2. MLFLow Infos",id:"2-mlflow-infos",level:3},{value:"3. Save MLFLow Infos",id:"3-save-mlflow-infos",level:3},{value:"MLFlow on Server",id:"mlflow-on-server",level:2},{value:"MLFlow Component",id:"mlflow-component-1",level:2},{value:"MLFlow Pipeline",id:"mlflow-pipeline",level:2},{value:"Data Component",id:"data-component",level:3},{value:"Pipeline",id:"pipeline",level:3},{value:"Run",id:"run",level:3}],d={toc:s},m="wrapper";function _(n){let{components:e,...l}=n;return(0,r.kt)(m,(0,t.Z)({},d,l,{components:e,mdxType:"MDXLayout"}),(0,r.kt)("h2",{id:"mlflow-component"},"MLFlow Component"),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"/docs/1.0/kubeflow/advanced-component"},"Advanced Usage Component")," \uc5d0\uc11c \ud559\uc2b5\ud55c \ubaa8\ub378\uc774 API Deployment\uae4c\uc9c0 \uc774\uc5b4\uc9c0\uae30 \uc704\ud574\uc11c\ub294 MLFlow\uc5d0 \ubaa8\ub378\uc744 \uc800\uc7a5\ud574\uc57c \ud569\ub2c8\ub2e4."),(0,r.kt)("p",null,"\uc774\ubc88 \ud398\uc774\uc9c0\uc5d0\uc11c\ub294 MLFlow\uc5d0 \ubaa8\ub378\uc744 \uc800\uc7a5\ud560 \uc218 \uc788\ub294 \ucef4\ud3ec\ub10c\ud2b8\ub97c \uc791\uc131\ud558\ub294 \uacfc\uc815\uc744 \uc124\uba85\ud569\ub2c8\ub2e4."),(0,r.kt)("h2",{id:"mlflow-in-local"},"MLFlow in Local"),(0,r.kt)("p",null,"MLFlow\uc5d0\uc11c \ubaa8\ub378\uc744 \uc800\uc7a5\ud558\uace0 \uc11c\ube59\uc5d0\uc11c \uc0ac\uc6a9\ud558\uae30 \uc704\ud574\uc11c\ub294 \ub2e4\uc74c\uc758 \ud56d\ubaa9\ub4e4\uc774 \ud544\uc694\ud569\ub2c8\ub2e4."),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"model"),(0,r.kt)("li",{parentName:"ul"},"signature"),(0,r.kt)("li",{parentName:"ul"},"input_example"),(0,r.kt)("li",{parentName:"ul"},"conda_env")),(0,r.kt)("p",null,"\ud30c\uc774\uc36c \ucf54\ub4dc\ub97c \ud1b5\ud574\uc11c MLFLow\uc5d0 \ubaa8\ub378\uc744 \uc800\uc7a5\ud558\ub294 \uacfc\uc815\uc5d0 \ub300\ud574\uc11c \uc54c\uc544\ubcf4\uaca0\uc2b5\ub2c8\ub2e4."),(0,r.kt)("h3",{id:"1-\ubaa8\ub378-\ud559\uc2b5"},"1. \ubaa8\ub378 \ud559\uc2b5"),(0,r.kt)("p",null,"\uc544\ub798 \uacfc\uc815\uc740 iris \ub370\uc774\ud130\ub97c \uc774\uc6a9\ud574 SVC \ubaa8\ub378\uc744 \ud559\uc2b5\ud558\ub294 \uacfc\uc815\uc785\ub2c8\ub2e4."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'import pandas as pd\nfrom sklearn.datasets import load_iris\nfrom sklearn.svm import SVC\n\niris = load_iris()\n\ndata = pd.DataFrame(iris["data"], columns=iris["feature_names"])\ntarget = pd.DataFrame(iris["target"], columns=["target"])\n\nclf = SVC(kernel="rbf")\nclf.fit(data, target)\n\n')),(0,r.kt)("h3",{id:"2-mlflow-infos"},"2. MLFLow Infos"),(0,r.kt)("p",null,"mlflow\uc5d0 \ud544\uc694\ud55c \uc815\ubcf4\ub4e4\uc744 \ub9cc\ub4dc\ub294 \uacfc\uc815\uc785\ub2c8\ub2e4."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from mlflow.models.signature import infer_signature\nfrom mlflow.utils.environment import _mlflow_conda_env\n\ninput_example = data.sample(1)\nsignature = infer_signature(data, clf.predict(data))\nconda_env = _mlflow_conda_env(additional_pip_deps=["dill", "pandas", "scikit-learn"])\n')),(0,r.kt)("p",null,"\uac01 \ubcc0\uc218\uc758 \ub0b4\uc6a9\uc744 \ud655\uc778\ud558\uba74 \ub2e4\uc74c\uacfc \uac19\uc2b5\ub2c8\ub2e4."),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("inlineCode",{parentName:"p"},"input_example")),(0,r.kt)("table",{parentName:"li"},(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null},"sepal length (cm)"),(0,r.kt)("th",{parentName:"tr",align:null},"sepal width (cm)"),(0,r.kt)("th",{parentName:"tr",align:null},"petal length (cm)"),(0,r.kt)("th",{parentName:"tr",align:null},"petal width (cm)"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"6.5"),(0,r.kt)("td",{parentName:"tr",align:null},"6.7"),(0,r.kt)("td",{parentName:"tr",align:null},"3.1"),(0,r.kt)("td",{parentName:"tr",align:null},"4.4"))))),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("inlineCode",{parentName:"p"},"signature")),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-python"},"inputs:\n  ['sepal length (cm)': double, 'sepal width (cm)': double, 'petal length (cm)': double, 'petal width (cm)': double]\noutputs:\n  [Tensor('int64', (-1,))]\n"))),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("inlineCode",{parentName:"p"},"conda_env")),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-python"},"{'name': 'mlflow-env',\n 'channels': ['conda-forge'],\n 'dependencies': ['python=3.8.10',\n  'pip',\n  {'pip': ['mlflow', 'dill', 'pandas', 'scikit-learn']}]}\n")))),(0,r.kt)("h3",{id:"3-save-mlflow-infos"},"3. Save MLFLow Infos"),(0,r.kt)("p",null,"\ub2e4\uc74c\uc73c\ub85c \ud559\uc2b5\ud55c \uc815\ubcf4\ub4e4\uacfc \ubaa8\ub378\uc744 \uc800\uc7a5\ud569\ub2c8\ub2e4.\n\ud559\uc2b5\ud55c \ubaa8\ub378\uc774 sklearn \ud328\ud0a4\uc9c0\ub97c \uc774\uc6a9\ud558\uae30 \ub54c\ubb38\uc5d0 ",(0,r.kt)("inlineCode",{parentName:"p"},"mlflow.sklearn")," \uc744 \uc774\uc6a9\ud558\uba74 \uc27d\uac8c \ubaa8\ub378\uc744 \uc800\uc7a5\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from mlflow.sklearn import save_model\n\nsave_model(\n    sk_model=clf,\n    path="svc",\n    serialization_format="cloudpickle",\n    conda_env=conda_env,\n    signature=signature,\n    input_example=input_example,\n)\n')),(0,r.kt)("p",null,"\ub85c\uceec\uc5d0\uc11c \uc791\uc5c5\ud558\uba74 \ub2e4\uc74c\uacfc \uac19\uc740 svc \ud3f4\ub354\uac00 \uc0dd\uae30\uba70 \uc544\ub798\uc640 \uac19\uc740 \ud30c\uc77c\ub4e4\uc774 \uc0dd\uc131\ub429\ub2c8\ub2e4."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"ls svc\n")),(0,r.kt)("p",null,"\uc704\uc758 \uba85\ub839\uc5b4\ub97c \uc2e4\ud589\ud558\uba74 \ub2e4\uc74c\uc758 \ucd9c\ub825\uac12\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"MLmodel            conda.yaml         input_example.json model.pkl          requirements.txt\n")),(0,r.kt)("p",null,"\uac01 \ud30c\uc77c\uc744 \ud655\uc778\ud558\uba74 \ub2e4\uc74c\uacfc \uac19\uc2b5\ub2c8\ub2e4."),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"MLmodel"),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-bash"},'flavors:\n  python_function:\n    env: conda.yaml\n    loader_module: mlflow.sklearn\n    model_path: model.pkl\n    python_version: 3.8.10\n  sklearn:\n    pickled_model: model.pkl\n    serialization_format: cloudpickle\n    sklearn_version: 1.0.1\nsaved_input_example_info:\n  artifact_path: input_example.json\n  pandas_orient: split\n  type: dataframe\nsignature:\n  inputs: \'[{"name": "sepal length (cm)", "type": "double"}, {"name": "sepal width\n    (cm)", "type": "double"}, {"name": "petal length (cm)", "type": "double"}, {"name":\n    "petal width (cm)", "type": "double"}]\'\n  outputs: \'[{"type": "tensor", "tensor-spec": {"dtype": "int64", "shape": [-1]}}]\'\nutc_time_created: \'2021-12-06 06:52:30.612810\'\n'))),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"conda.yaml"),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"channels:\n- conda-forge\ndependencies:\n- python=3.8.10\n- pip\n- pip:\n  - mlflow\n  - dill\n  - pandas\n  - scikit-learn\nname: mlflow-env\n"))),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"input_example.json"),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-bash"},'{\n    "columns": \n    [\n        "sepal length (cm)",\n        "sepal width (cm)",\n        "petal length (cm)",\n        "petal width (cm)"\n    ],\n    "data": \n    [\n        [6.7, 3.1, 4.4, 1.4]\n    ]\n}\n'))),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"requirements.txt"),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"mlflow\ndill\npandas\nscikit-learn\n"))),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"model.pkl"))),(0,r.kt)("h2",{id:"mlflow-on-server"},"MLFlow on Server"),(0,r.kt)("p",null,"\uc774\uc81c \uc800\uc7a5\ub41c \ubaa8\ub378\uc744 mlflow \uc11c\ubc84\uc5d0 \uc62c\ub9ac\ub294 \uc791\uc5c5\uc744 \ud574\ubcf4\uaca0\uc2b5\ub2c8\ub2e4."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'import mlflow\n\nwith mlflow.start_run():\n    mlflow.log_artifact("svc/")\n')),(0,r.kt)("p",null,"\uc800\uc7a5\ud558\uace0 ",(0,r.kt)("inlineCode",{parentName:"p"},"mlruns")," \uac00 \uc0dd\uc131\ub41c \uacbd\ub85c\uc5d0\uc11c ",(0,r.kt)("inlineCode",{parentName:"p"},"mlflow ui")," \uba85\ub839\uc5b4\ub97c \uc774\uc6a9\ud574 mlflow \uc11c\ubc84\uc640 \ub300\uc2dc\ubcf4\ub4dc\ub97c \ub744\uc6c1\ub2c8\ub2e4.\nmlflow \ub300\uc2dc\ubcf4\ub4dc\uc5d0 \uc811\uc18d\ud558\uc5ec \uc0dd\uc131\ub41c run\uc744 \ud074\ub9ad\ud558\uba74 \ub2e4\uc74c\uacfc \uac19\uc774 \ubcf4\uc785\ub2c8\ub2e4."),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"mlflow-0.png",src:a(3810).Z,width:"2782",height:"2496"}),"\n(\ud574\ub2f9 \ud654\uba74\uc740 mlflow \ubc84\uc804\uc5d0 \ub530\ub77c \ub2e4\ub97c \uc218 \uc788\uc2b5\ub2c8\ub2e4.)"),(0,r.kt)("h2",{id:"mlflow-component-1"},"MLFlow Component"),(0,r.kt)("p",null,"\uc774\uc81c Kubeflow\uc5d0\uc11c \uc7ac\uc0ac\uc6a9\ud560 \uc218 \uc788\ub294 \ucef4\ud3ec\ub10c\ud2b8\ub97c \uc791\uc131\ud574 \ubcf4\uaca0\uc2b5\ub2c8\ub2e4."),(0,r.kt)("p",null,"\uc7ac\uc0ac\uc6a9\ud560 \uc218 \uc788\ub294 \ucef4\ud3ec\ub10c\ud2b8\ub97c \uc791\uc131\ud558\ub294 \ubc29\ubc95\uc740 \ud06c\uac8c 3\uac00\uc9c0\uac00 \uc788\uc2b5\ub2c8\ub2e4."),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"\ubaa8\ub378\uc744 \ud559\uc2b5\ud558\ub294 \ucef4\ud3ec\ub10c\ud2b8\uc5d0\uc11c \ud544\uc694\ud55c \ud658\uacbd\uc744 \uc800\uc7a5 \ud6c4 MLFlow \ucef4\ud3ec\ub10c\ud2b8\ub294 \uc5c5\ub85c\ub4dc\ub9cc \ub2f4\ub2f9"),(0,r.kt)("p",{parentName:"li"},(0,r.kt)("img",{alt:"mlflow-1.png",src:a(8705).Z,width:"578",height:"844"}))),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"\ud559\uc2b5\ub41c \ubaa8\ub378\uacfc \ub370\uc774\ud130\ub97c MLFlow \ucef4\ud3ec\ub10c\ud2b8\uc5d0 \uc804\ub2ec \ud6c4 \ucef4\ud3ec\ub10c\ud2b8\uc5d0\uc11c \uc800\uc7a5\uacfc \uc5c5\ub85c\ub4dc \ub2f4\ub2f9"),(0,r.kt)("p",{parentName:"li"},(0,r.kt)("img",{alt:"mlflow-2.png",src:a(9481).Z,width:"900",height:"846"}))),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"\ubaa8\ub378\uc744 \ud559\uc2b5\ud558\ub294 \ucef4\ud3ec\ub10c\ud2b8\uc5d0\uc11c \uc800\uc7a5\uacfc \uc5c5\ub85c\ub4dc\ub97c \ub2f4\ub2f9"),(0,r.kt)("p",{parentName:"li"},(0,r.kt)("img",{alt:"mlflow-3.png",src:a(3268).Z,width:"578",height:"406"})))),(0,r.kt)("p",null,"\uc800\ud76c\ub294 \uc774 \uc911 1\ubc88\uc758 \uc811\uadfc \ubc29\ubc95\uc744 \ud1b5\ud574 \ubaa8\ub378\uc744 \uad00\ub9ac\ud558\ub824\uace0 \ud569\ub2c8\ub2e4.\n\uc774\uc720\ub294 MLFlow \ubaa8\ub378\uc744 \uc5c5\ub85c\ub4dc\ud558\ub294 \ucf54\ub4dc\ub294 \ubc14\ub00c\uc9c0 \uc54a\uae30 \ub54c\ubb38\uc5d0 \ub9e4\ubc88 3\ubc88\ucc98\ub7fc \ucef4\ud3ec\ub10c\ud2b8 \uc791\uc131\ub9c8\ub2e4 \uc791\uc131\ud560 \ud544\uc694\ub294 \uc5c6\uae30 \ub54c\ubb38\uc785\ub2c8\ub2e4."),(0,r.kt)("p",null,"\ucef4\ud3ec\ub10c\ud2b8\ub97c \uc7ac\ud65c\uc6a9\ud558\ub294 \ubc29\ubc95\uc740 1\ubc88\uacfc 2\ubc88\uc758 \ubc29\ubc95\uc73c\ub85c \uac00\ub2a5\ud569\ub2c8\ub2e4.\n\ub2e4\ub9cc 2\ubc88\uc758 \uacbd\uc6b0 \ubaa8\ub378\uc774 \ud559\uc2b5\ub41c \uc774\ubbf8\uc9c0\uc640 \ud328\ud0a4\uc9c0\ub4e4\uc744 \uc804\ub2ec\ud574\uc57c \ud558\ubbc0\ub85c \uacb0\uad6d \ucef4\ud3ec\ub10c\ud2b8\uc5d0 \ub300\ud55c \ucd94\uac00 \uc815\ubcf4\ub97c \uc804\ub2ec\ud574\uc57c \ud569\ub2c8\ub2e4."),(0,r.kt)("p",null,"1\ubc88\uc758 \ubc29\ubc95\uc73c\ub85c \uc9c4\ud589\ud558\uae30 \uc704\ud574\uc11c\ub294 \ud559\uc2b5\ud558\ub294 \ucef4\ud3ec\ub10c\ud2b8 \ub610\ud55c \ubcc0\uacbd\ub418\uc5b4\uc57c \ud569\ub2c8\ub2e4.\n\ubaa8\ub378\uc744 \uc800\uc7a5\ud558\ub294\ub370 \ud544\uc694\ud55c \ud658\uacbd\ub4e4\uc744 \uc800\uc7a5\ud574\uc8fc\ub294 \ucf54\ub4dc\uac00 \ucd94\uac00\ub418\uc5b4\uc57c \ud569\ub2c8\ub2e4."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from functools import partial\nfrom kfp.components import InputPath, OutputPath, create_component_from_func\n\n@partial(\n    create_component_from_func,\n    packages_to_install=["dill", "pandas", "scikit-learn", "mlflow"],\n)\ndef train_from_csv(\n    train_data_path: InputPath("csv"),\n    train_target_path: InputPath("csv"),\n    model_path: OutputPath("dill"),\n    input_example_path: OutputPath("dill"),\n    signature_path: OutputPath("dill"),\n    conda_env_path: OutputPath("dill"),\n    kernel: str,\n):\n    import dill\n    import pandas as pd\n    from sklearn.svm import SVC\n\n    from mlflow.models.signature import infer_signature\n    from mlflow.utils.environment import _mlflow_conda_env\n\n    train_data = pd.read_csv(train_data_path)\n    train_target = pd.read_csv(train_target_path)\n\n    clf = SVC(kernel=kernel)\n    clf.fit(train_data, train_target)\n\n    with open(model_path, mode="wb") as file_writer:\n        dill.dump(clf, file_writer)\n\n    input_example = train_data.sample(1)\n    with open(input_example_path, "wb") as file_writer:\n        dill.dump(input_example, file_writer)\n\n    signature = infer_signature(train_data, clf.predict(train_data))\n    with open(signature_path, "wb") as file_writer:\n        dill.dump(signature, file_writer)\n\n    conda_env = _mlflow_conda_env(\n        additional_pip_deps=["dill", "pandas", "scikit-learn"]\n    )\n    with open(conda_env_path, "wb") as file_writer:\n        dill.dump(conda_env, file_writer)\n\n')),(0,r.kt)("p",null,"\uadf8\ub9ac\uace0 MLFlow\uc5d0 \uc5c5\ub85c\ub4dc\ud558\ub294 \ucef4\ud3ec\ub10c\ud2b8\ub97c \uc791\uc131\ud569\ub2c8\ub2e4.\n\uc774 \ub54c \uc5c5\ub85c\ub4dc\ub418\ub294 MLflow\uc758 endpoint\ub97c \uc6b0\ub9ac\uac00 \uc124\uce58\ud55c ",(0,r.kt)("a",{parentName:"p",href:"/docs/1.0/setup-components/install-components-mlflow"},"mlflow service")," \ub85c \uc774\uc5b4\uc9c0\uac8c \uc124\uc815\ud574\uc8fc\uc5b4\uc57c \ud569\ub2c8\ub2e4.",(0,r.kt)("br",{parentName:"p"}),"\n","\uc774 \ub54c S3 Endpoint\uc758 \uc8fc\uc18c\ub294 MLflow Server \uc124\uce58 \ub2f9\uc2dc \uc124\uce58\ud55c minio\uc758 ",(0,r.kt)("a",{parentName:"p",href:"https://kubernetes.io/ko/docs/concepts/services-networking/dns-pod-service/"},"\ucfe0\ubc84\ub124\ud2f0\uc2a4 \uc11c\ube44\uc2a4 DNS \ub124\uc784\uc744 \ud65c\uc6a9"),"\ud569\ub2c8\ub2e4. \ud574\ub2f9 service \ub294 kubeflow namespace\uc5d0\uc11c minio-service\ub77c\ub294 \uc774\ub984\uc73c\ub85c \uc0dd\uc131\ub418\uc5c8\uc73c\ubbc0\ub85c, ",(0,r.kt)("inlineCode",{parentName:"p"},"http://minio-service.kubeflow.svc:9000")," \ub85c \uc124\uc815\ud569\ub2c8\ub2e4.",(0,r.kt)("br",{parentName:"p"}),"\n","\uc774\uc640 \ube44\uc2b7\ud558\uac8c tracking_uri\uc758 \uc8fc\uc18c\ub294 mlflow server\uc758 \ucfe0\ubc84\ub124\ud2f0\uc2a4 \uc11c\ube44\uc2a4 DNS \ub124\uc784\uc744 \ud65c\uc6a9\ud558\uc5ec, ",(0,r.kt)("inlineCode",{parentName:"p"},"http://mlflow-server-service.mlflow-system.svc:5000")," \ub85c \uc124\uc815\ud569\ub2c8\ub2e4."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from functools import partial\nfrom kfp.components import InputPath, create_component_from_func\n\n@partial(\n    create_component_from_func,\n    packages_to_install=["dill", "pandas", "scikit-learn", "mlflow", "boto3"],\n)\ndef upload_sklearn_model_to_mlflow(\n    model_name: str,\n    model_path: InputPath("dill"),\n    input_example_path: InputPath("dill"),\n    signature_path: InputPath("dill"),\n    conda_env_path: InputPath("dill"),\n):\n    import os\n    import dill\n    from mlflow.sklearn import save_model\n    \n    from mlflow.tracking.client import MlflowClient\n\n    os.environ["MLFLOW_S3_ENDPOINT_URL"] = "http://minio-service.kubeflow.svc:9000"\n    os.environ["AWS_ACCESS_KEY_ID"] = "minio"\n    os.environ["AWS_SECRET_ACCESS_KEY"] = "minio123"\n\n    client = MlflowClient("http://mlflow-server-service.mlflow-system.svc:5000")\n\n    with open(model_path, mode="rb") as file_reader:\n        clf = dill.load(file_reader)\n\n    with open(input_example_path, "rb") as file_reader:\n        input_example = dill.load(file_reader)\n\n    with open(signature_path, "rb") as file_reader:\n        signature = dill.load(file_reader)\n\n    with open(conda_env_path, "rb") as file_reader:\n        conda_env = dill.load(file_reader)\n\n    save_model(\n        sk_model=clf,\n        path=model_name,\n        serialization_format="cloudpickle",\n        conda_env=conda_env,\n        signature=signature,\n        input_example=input_example,\n    )\n    run = client.create_run(experiment_id="0")\n    client.log_artifact(run.info.run_id, model_name)\n')),(0,r.kt)("h2",{id:"mlflow-pipeline"},"MLFlow Pipeline"),(0,r.kt)("p",null,"\uc774\uc81c \uc791\uc131\ud55c \ucef4\ud3ec\ub10c\ud2b8\ub4e4\uc744 \uc5f0\uacb0\ud574\uc11c \ud30c\uc774\ud504\ub77c\uc778\uc73c\ub85c \ub9cc\ub4e4\uc5b4 \ubcf4\uaca0\uc2b5\ub2c8\ub2e4."),(0,r.kt)("h3",{id:"data-component"},"Data Component"),(0,r.kt)("p",null,"\ubaa8\ub378\uc744 \ud559\uc2b5\ud560 \ub54c \uc4f8 \ub370\uc774\ud130\ub294 sklearn\uc758 iris \uc785\ub2c8\ub2e4.\n\ub370\uc774\ud130\ub97c \uc0dd\uc131\ud558\ub294 \ucef4\ud3ec\ub10c\ud2b8\ub97c \uc791\uc131\ud569\ub2c8\ub2e4."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from functools import partial\n\nfrom kfp.components import InputPath, OutputPath, create_component_from_func\n\n\n@partial(\n    create_component_from_func,\n    packages_to_install=["pandas", "scikit-learn"],\n)\ndef load_iris_data(\n    data_path: OutputPath("csv"),\n    target_path: OutputPath("csv"),\n):\n    import pandas as pd\n    from sklearn.datasets import load_iris\n\n    iris = load_iris()\n\n    data = pd.DataFrame(iris["data"], columns=iris["feature_names"])\n    target = pd.DataFrame(iris["target"], columns=["target"])\n\n    data.to_csv(data_path, index=False)\n    target.to_csv(target_path, index=False)\n\n')),(0,r.kt)("h3",{id:"pipeline"},"Pipeline"),(0,r.kt)("p",null,"\ud30c\uc774\ud504\ub77c\uc778 \ucf54\ub4dc\ub294 \ub2e4\uc74c\uacfc \uac19\uc774 \uc791\uc131\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from kfp.dsl import pipeline\n\n\n@pipeline(name="mlflow_pipeline")\ndef mlflow_pipeline(kernel: str, model_name: str):\n    iris_data = load_iris_data()\n    model = train_from_csv(\n        train_data=iris_data.outputs["data"],\n        train_target=iris_data.outputs["target"],\n        kernel=kernel,\n    )\n    _ = upload_sklearn_model_to_mlflow(\n        model_name=model_name,\n        model=model.outputs["model"],\n        input_example=model.outputs["input_example"],\n        signature=model.outputs["signature"],\n        conda_env=model.outputs["conda_env"],\n    )\n')),(0,r.kt)("h3",{id:"run"},"Run"),(0,r.kt)("p",null,"\uc704\uc5d0\uc11c \uc791\uc131\ub41c \ucef4\ud3ec\ub10c\ud2b8\uc640 \ud30c\uc774\ud504\ub77c\uc778\uc744 \ud558\ub098\uc758 \ud30c\uc774\uc36c \ud30c\uc77c\uc5d0 \uc815\ub9ac\ud558\uba74 \ub2e4\uc74c\uacfc \uac19\uc2b5\ub2c8\ub2e4."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from functools import partial\n\nimport kfp\nfrom kfp.components import InputPath, OutputPath, create_component_from_func\nfrom kfp.dsl import pipeline\n\n\n@partial(\n    create_component_from_func,\n    packages_to_install=["pandas", "scikit-learn"],\n)\ndef load_iris_data(\n    data_path: OutputPath("csv"),\n    target_path: OutputPath("csv"),\n):\n    import pandas as pd\n    from sklearn.datasets import load_iris\n\n    iris = load_iris()\n\n    data = pd.DataFrame(iris["data"], columns=iris["feature_names"])\n    target = pd.DataFrame(iris["target"], columns=["target"])\n\n    data.to_csv(data_path, index=False)\n    target.to_csv(target_path, index=False)\n\n\n@partial(\n    create_component_from_func,\n    packages_to_install=["dill", "pandas", "scikit-learn", "mlflow"],\n)\ndef train_from_csv(\n    train_data_path: InputPath("csv"),\n    train_target_path: InputPath("csv"),\n    model_path: OutputPath("dill"),\n    input_example_path: OutputPath("dill"),\n    signature_path: OutputPath("dill"),\n    conda_env_path: OutputPath("dill"),\n    kernel: str,\n):\n    import dill\n    import pandas as pd\n    from sklearn.svm import SVC\n\n    from mlflow.models.signature import infer_signature\n    from mlflow.utils.environment import _mlflow_conda_env\n\n    train_data = pd.read_csv(train_data_path)\n    train_target = pd.read_csv(train_target_path)\n\n    clf = SVC(kernel=kernel)\n    clf.fit(train_data, train_target)\n\n    with open(model_path, mode="wb") as file_writer:\n        dill.dump(clf, file_writer)\n\n    input_example = train_data.sample(1)\n    with open(input_example_path, "wb") as file_writer:\n        dill.dump(input_example, file_writer)\n\n    signature = infer_signature(train_data, clf.predict(train_data))\n    with open(signature_path, "wb") as file_writer:\n        dill.dump(signature, file_writer)\n\n    conda_env = _mlflow_conda_env(\n        additional_pip_deps=["dill", "pandas", "scikit-learn"]\n    )\n    with open(conda_env_path, "wb") as file_writer:\n        dill.dump(conda_env, file_writer)\n\n\n@partial(\n    create_component_from_func,\n    packages_to_install=["dill", "pandas", "scikit-learn", "mlflow", "boto3"],\n)\ndef upload_sklearn_model_to_mlflow(\n    model_name: str,\n    model_path: InputPath("dill"),\n    input_example_path: InputPath("dill"),\n    signature_path: InputPath("dill"),\n    conda_env_path: InputPath("dill"),\n):\n    import os\n    import dill\n    from mlflow.sklearn import save_model\n    \n    from mlflow.tracking.client import MlflowClient\n\n    os.environ["MLFLOW_S3_ENDPOINT_URL"] = "http://minio-service.kubeflow.svc:9000"\n    os.environ["AWS_ACCESS_KEY_ID"] = "minio"\n    os.environ["AWS_SECRET_ACCESS_KEY"] = "minio123"\n\n    client = MlflowClient("http://mlflow-server-service.mlflow-system.svc:5000")\n\n    with open(model_path, mode="rb") as file_reader:\n        clf = dill.load(file_reader)\n\n    with open(input_example_path, "rb") as file_reader:\n        input_example = dill.load(file_reader)\n\n    with open(signature_path, "rb") as file_reader:\n        signature = dill.load(file_reader)\n\n    with open(conda_env_path, "rb") as file_reader:\n        conda_env = dill.load(file_reader)\n\n    save_model(\n        sk_model=clf,\n        path=model_name,\n        serialization_format="cloudpickle",\n        conda_env=conda_env,\n        signature=signature,\n        input_example=input_example,\n    )\n    run = client.create_run(experiment_id="0")\n    client.log_artifact(run.info.run_id, model_name)\n\n\n@pipeline(name="mlflow_pipeline")\ndef mlflow_pipeline(kernel: str, model_name: str):\n    iris_data = load_iris_data()\n    model = train_from_csv(\n        train_data=iris_data.outputs["data"],\n        train_target=iris_data.outputs["target"],\n        kernel=kernel,\n    )\n    _ = upload_sklearn_model_to_mlflow(\n        model_name=model_name,\n        model=model.outputs["model"],\n        input_example=model.outputs["input_example"],\n        signature=model.outputs["signature"],\n        conda_env=model.outputs["conda_env"],\n    )\n\n\nif __name__ == "__main__":\n    kfp.compiler.Compiler().compile(mlflow_pipeline, "mlflow_pipeline.yaml")\n')),(0,r.kt)("p",null,(0,r.kt)("details",null,(0,r.kt)("summary",null,"mlflow_pipeline.yaml"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},'apiVersion: argoproj.io/v1alpha1\nkind: Workflow\nmetadata:\n  generateName: mlflow-pipeline-\n  annotations: {pipelines.kubeflow.org/kfp_sdk_version: 1.8.10, pipelines.kubeflow.org/pipeline_compilation_time: \'2022-01-19T14:14:11.999807\',\n    pipelines.kubeflow.org/pipeline_spec: \'{"inputs": [{"name": "kernel", "type":\n      "String"}, {"name": "model_name", "type": "String"}], "name": "mlflow_pipeline"}\'}\n  labels: {pipelines.kubeflow.org/kfp_sdk_version: 1.8.10}\nspec:\n  entrypoint: mlflow-pipeline\n  templates:\n  - name: load-iris-data\n    container:\n      args: [--data, /tmp/outputs/data/data, --target, /tmp/outputs/target/data]\n      command:\n      - sh\n      - -c\n      - (PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location\n        \'pandas\' \'scikit-learn\' || PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip\n        install --quiet --no-warn-script-location \'pandas\' \'scikit-learn\' --user)\n        && "$0" "$@"\n      - sh\n      - -ec\n      - |\n        program_path=$(mktemp)\n        printf "%s" "$0" > "$program_path"\n        python3 -u "$program_path" "$@"\n      - |\n        def _make_parent_dirs_and_return_path(file_path: str):\n            import os\n            os.makedirs(os.path.dirname(file_path), exist_ok=True)\n            return file_path\n\n        def load_iris_data(\n            data_path,\n            target_path,\n        ):\n            import pandas as pd\n            from sklearn.datasets import load_iris\n\n            iris = load_iris()\n\n            data = pd.DataFrame(iris["data"], columns=iris["feature_names"])\n            target = pd.DataFrame(iris["target"], columns=["target"])\n\n            data.to_csv(data_path, index=False)\n            target.to_csv(target_path, index=False)\n\n        import argparse\n        _parser = argparse.ArgumentParser(prog=\'Load iris data\', description=\'\')\n        _parser.add_argument("--data", dest="data_path", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)\n        _parser.add_argument("--target", dest="target_path", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)\n        _parsed_args = vars(_parser.parse_args())\n\n        _outputs = load_iris_data(**_parsed_args)\n      image: python:3.7\n    outputs:\n      artifacts:\n      - {name: load-iris-data-data, path: /tmp/outputs/data/data}\n      - {name: load-iris-data-target, path: /tmp/outputs/target/data}\n    metadata:\n      labels:\n        pipelines.kubeflow.org/kfp_sdk_version: 1.8.10\n        pipelines.kubeflow.org/pipeline-sdk-type: kfp\n        pipelines.kubeflow.org/enable_caching: "true"\n      annotations: {pipelines.kubeflow.org/component_spec: \'{"implementation": {"container":\n          {"args": ["--data", {"outputPath": "data"}, "--target", {"outputPath": "target"}],\n          "command": ["sh", "-c", "(PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip\n          install --quiet --no-warn-script-location \'\'pandas\'\' \'\'scikit-learn\'\' ||\n          PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location\n          \'\'pandas\'\' \'\'scikit-learn\'\' --user) && \\"$0\\" \\"$@\\"", "sh", "-ec", "program_path=$(mktemp)\\nprintf\n          \\"%s\\" \\"$0\\" > \\"$program_path\\"\\npython3 -u \\"$program_path\\" \\"$@\\"\\n",\n          "def _make_parent_dirs_and_return_path(file_path: str):\\n    import os\\n    os.makedirs(os.path.dirname(file_path),\n          exist_ok=True)\\n    return file_path\\n\\ndef load_iris_data(\\n    data_path,\\n    target_path,\\n):\\n    import\n          pandas as pd\\n    from sklearn.datasets import load_iris\\n\\n    iris = load_iris()\\n\\n    data\n          = pd.DataFrame(iris[\\"data\\"], columns=iris[\\"feature_names\\"])\\n    target\n          = pd.DataFrame(iris[\\"target\\"], columns=[\\"target\\"])\\n\\n    data.to_csv(data_path,\n          index=False)\\n    target.to_csv(target_path, index=False)\\n\\nimport argparse\\n_parser\n          = argparse.ArgumentParser(prog=\'\'Load iris data\'\', description=\'\'\'\')\\n_parser.add_argument(\\"--data\\",\n          dest=\\"data_path\\", type=_make_parent_dirs_and_return_path, required=True,\n          default=argparse.SUPPRESS)\\n_parser.add_argument(\\"--target\\", dest=\\"target_path\\",\n          type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)\\n_parsed_args\n          = vars(_parser.parse_args())\\n\\n_outputs = load_iris_data(**_parsed_args)\\n"],\n          "image": "python:3.7"}}, "name": "Load iris data", "outputs": [{"name":\n          "data", "type": "csv"}, {"name": "target", "type": "csv"}]}\', pipelines.kubeflow.org/component_ref: \'{}\'}\n  - name: mlflow-pipeline\n    inputs:\n      parameters:\n      - {name: kernel}\n      - {name: model_name}\n    dag:\n      tasks:\n      - {name: load-iris-data, template: load-iris-data}\n      - name: train-from-csv\n        template: train-from-csv\n        dependencies: [load-iris-data]\n        arguments:\n          parameters:\n          - {name: kernel, value: \'{{inputs.parameters.kernel}}\'}\n          artifacts:\n          - {name: load-iris-data-data, from: \'{{tasks.load-iris-data.outputs.artifacts.load-iris-data-data}}\'}\n          - {name: load-iris-data-target, from: \'{{tasks.load-iris-data.outputs.artifacts.load-iris-data-target}}\'}\n      - name: upload-sklearn-model-to-mlflow\n        template: upload-sklearn-model-to-mlflow\n        dependencies: [train-from-csv]\n        arguments:\n          parameters:\n          - {name: model_name, value: \'{{inputs.parameters.model_name}}\'}\n          artifacts:\n          - {name: train-from-csv-conda_env, from: \'{{tasks.train-from-csv.outputs.artifacts.train-from-csv-conda_env}}\'}\n          - {name: train-from-csv-input_example, from: \'{{tasks.train-from-csv.outputs.artifacts.train-from-csv-input_example}}\'}\n          - {name: train-from-csv-model, from: \'{{tasks.train-from-csv.outputs.artifacts.train-from-csv-model}}\'}\n          - {name: train-from-csv-signature, from: \'{{tasks.train-from-csv.outputs.artifacts.train-from-csv-signature}}\'}\n  - name: train-from-csv\n    container:\n      args: [--train-data, /tmp/inputs/train_data/data, --train-target, /tmp/inputs/train_target/data,\n        --kernel, \'{{inputs.parameters.kernel}}\', --model, /tmp/outputs/model/data,\n        --input-example, /tmp/outputs/input_example/data, --signature, /tmp/outputs/signature/data,\n        --conda-env, /tmp/outputs/conda_env/data]\n      command:\n      - sh\n      - -c\n      - (PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location\n        \'dill\' \'pandas\' \'scikit-learn\' \'mlflow\' || PIP_DISABLE_PIP_VERSION_CHECK=1\n        python3 -m pip install --quiet --no-warn-script-location \'dill\' \'pandas\' \'scikit-learn\'\n        \'mlflow\' --user) && "$0" "$@"\n      - sh\n      - -ec\n      - |\n        program_path=$(mktemp)\n        printf "%s" "$0" > "$program_path"\n        python3 -u "$program_path" "$@"\n      - |\n        def _make_parent_dirs_and_return_path(file_path: str):\n            import os\n            os.makedirs(os.path.dirname(file_path), exist_ok=True)\n            return file_path\n\n        def train_from_csv(\n            train_data_path,\n            train_target_path,\n            model_path,\n            input_example_path,\n            signature_path,\n            conda_env_path,\n            kernel,\n        ):\n            import dill\n            import pandas as pd\n            from sklearn.svm import SVC\n\n            from mlflow.models.signature import infer_signature\n            from mlflow.utils.environment import _mlflow_conda_env\n\n            train_data = pd.read_csv(train_data_path)\n            train_target = pd.read_csv(train_target_path)\n\n            clf = SVC(kernel=kernel)\n            clf.fit(train_data, train_target)\n\n            with open(model_path, mode="wb") as file_writer:\n                dill.dump(clf, file_writer)\n\n            input_example = train_data.sample(1)\n            with open(input_example_path, "wb") as file_writer:\n                dill.dump(input_example, file_writer)\n\n            signature = infer_signature(train_data, clf.predict(train_data))\n            with open(signature_path, "wb") as file_writer:\n                dill.dump(signature, file_writer)\n\n            conda_env = _mlflow_conda_env(\n                additional_pip_deps=["dill", "pandas", "scikit-learn"]\n            )\n            with open(conda_env_path, "wb") as file_writer:\n                dill.dump(conda_env, file_writer)\n\n        import argparse\n        _parser = argparse.ArgumentParser(prog=\'Train from csv\', description=\'\')\n        _parser.add_argument("--train-data", dest="train_data_path", type=str, required=True, default=argparse.SUPPRESS)\n        _parser.add_argument("--train-target", dest="train_target_path", type=str, required=True, default=argparse.SUPPRESS)\n        _parser.add_argument("--kernel", dest="kernel", type=str, required=True, default=argparse.SUPPRESS)\n        _parser.add_argument("--model", dest="model_path", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)\n        _parser.add_argument("--input-example", dest="input_example_path", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)\n        _parser.add_argument("--signature", dest="signature_path", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)\n        _parser.add_argument("--conda-env", dest="conda_env_path", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)\n        _parsed_args = vars(_parser.parse_args())\n\n        _outputs = train_from_csv(**_parsed_args)\n      image: python:3.7\n    inputs:\n      parameters:\n      - {name: kernel}\n      artifacts:\n      - {name: load-iris-data-data, path: /tmp/inputs/train_data/data}\n      - {name: load-iris-data-target, path: /tmp/inputs/train_target/data}\n    outputs:\n      artifacts:\n      - {name: train-from-csv-conda_env, path: /tmp/outputs/conda_env/data}\n      - {name: train-from-csv-input_example, path: /tmp/outputs/input_example/data}\n      - {name: train-from-csv-model, path: /tmp/outputs/model/data}\n      - {name: train-from-csv-signature, path: /tmp/outputs/signature/data}\n    metadata:\n      labels:\n        pipelines.kubeflow.org/kfp_sdk_version: 1.8.10\n        pipelines.kubeflow.org/pipeline-sdk-type: kfp\n        pipelines.kubeflow.org/enable_caching: "true"\n      annotations: {pipelines.kubeflow.org/component_spec: \'{"implementation": {"container":\n          {"args": ["--train-data", {"inputPath": "train_data"}, "--train-target",\n          {"inputPath": "train_target"}, "--kernel", {"inputValue": "kernel"}, "--model",\n          {"outputPath": "model"}, "--input-example", {"outputPath": "input_example"},\n          "--signature", {"outputPath": "signature"}, "--conda-env", {"outputPath":\n          "conda_env"}], "command": ["sh", "-c", "(PIP_DISABLE_PIP_VERSION_CHECK=1\n          python3 -m pip install --quiet --no-warn-script-location \'\'dill\'\' \'\'pandas\'\'\n          \'\'scikit-learn\'\' \'\'mlflow\'\' || PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m\n          pip install --quiet --no-warn-script-location \'\'dill\'\' \'\'pandas\'\' \'\'scikit-learn\'\'\n          \'\'mlflow\'\' --user) && \\"$0\\" \\"$@\\"", "sh", "-ec", "program_path=$(mktemp)\\nprintf\n          \\"%s\\" \\"$0\\" > \\"$program_path\\"\\npython3 -u \\"$program_path\\" \\"$@\\"\\n",\n          "def _make_parent_dirs_and_return_path(file_path: str):\\n    import os\\n    os.makedirs(os.path.dirname(file_path),\n          exist_ok=True)\\n    return file_path\\n\\ndef train_from_csv(\\n    train_data_path,\\n    train_target_path,\\n    model_path,\\n    input_example_path,\\n    signature_path,\\n    conda_env_path,\\n    kernel,\\n):\\n    import\n          dill\\n    import pandas as pd\\n    from sklearn.svm import SVC\\n\\n    from\n          mlflow.models.signature import infer_signature\\n    from mlflow.utils.environment\n          import _mlflow_conda_env\\n\\n    train_data = pd.read_csv(train_data_path)\\n    train_target\n          = pd.read_csv(train_target_path)\\n\\n    clf = SVC(kernel=kernel)\\n    clf.fit(train_data,\n          train_target)\\n\\n    with open(model_path, mode=\\"wb\\") as file_writer:\\n        dill.dump(clf,\n          file_writer)\\n\\n    input_example = train_data.sample(1)\\n    with open(input_example_path,\n          \\"wb\\") as file_writer:\\n        dill.dump(input_example, file_writer)\\n\\n    signature\n          = infer_signature(train_data, clf.predict(train_data))\\n    with open(signature_path,\n          \\"wb\\") as file_writer:\\n        dill.dump(signature, file_writer)\\n\\n    conda_env\n          = _mlflow_conda_env(\\n        additional_pip_deps=[\\"dill\\", \\"pandas\\",\n          \\"scikit-learn\\"]\\n    )\\n    with open(conda_env_path, \\"wb\\") as file_writer:\\n        dill.dump(conda_env,\n          file_writer)\\n\\nimport argparse\\n_parser = argparse.ArgumentParser(prog=\'\'Train\n          from csv\'\', description=\'\'\'\')\\n_parser.add_argument(\\"--train-data\\", dest=\\"train_data_path\\",\n          type=str, required=True, default=argparse.SUPPRESS)\\n_parser.add_argument(\\"--train-target\\",\n          dest=\\"train_target_path\\", type=str, required=True, default=argparse.SUPPRESS)\\n_parser.add_argument(\\"--kernel\\",\n          dest=\\"kernel\\", type=str, required=True, default=argparse.SUPPRESS)\\n_parser.add_argument(\\"--model\\",\n          dest=\\"model_path\\", type=_make_parent_dirs_and_return_path, required=True,\n          default=argparse.SUPPRESS)\\n_parser.add_argument(\\"--input-example\\", dest=\\"input_example_path\\",\n          type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)\\n_parser.add_argument(\\"--signature\\",\n          dest=\\"signature_path\\", type=_make_parent_dirs_and_return_path, required=True,\n          default=argparse.SUPPRESS)\\n_parser.add_argument(\\"--conda-env\\", dest=\\"conda_env_path\\",\n          type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)\\n_parsed_args\n          = vars(_parser.parse_args())\\n\\n_outputs = train_from_csv(**_parsed_args)\\n"],\n          "image": "python:3.7"}}, "inputs": [{"name": "train_data", "type": "csv"},\n          {"name": "train_target", "type": "csv"}, {"name": "kernel", "type": "String"}],\n          "name": "Train from csv", "outputs": [{"name": "model", "type": "dill"},\n          {"name": "input_example", "type": "dill"}, {"name": "signature", "type":\n          "dill"}, {"name": "conda_env", "type": "dill"}]}\', pipelines.kubeflow.org/component_ref: \'{}\',\n        pipelines.kubeflow.org/arguments.parameters: \'{"kernel": "{{inputs.parameters.kernel}}"}\'}\n  - name: upload-sklearn-model-to-mlflow\n    container:\n      args: [--model-name, \'{{inputs.parameters.model_name}}\', --model, /tmp/inputs/model/data,\n        --input-example, /tmp/inputs/input_example/data, --signature, /tmp/inputs/signature/data,\n        --conda-env, /tmp/inputs/conda_env/data]\n      command:\n      - sh\n      - -c\n      - (PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location\n        \'dill\' \'pandas\' \'scikit-learn\' \'mlflow\' \'boto3\' || PIP_DISABLE_PIP_VERSION_CHECK=1\n        python3 -m pip install --quiet --no-warn-script-location \'dill\' \'pandas\' \'scikit-learn\'\n        \'mlflow\' \'boto3\' --user) && "$0" "$@"\n      - sh\n      - -ec\n      - |\n        program_path=$(mktemp)\n        printf "%s" "$0" > "$program_path"\n        python3 -u "$program_path" "$@"\n      - |\n        def upload_sklearn_model_to_mlflow(\n            model_name,\n            model_path,\n            input_example_path,\n            signature_path,\n            conda_env_path,\n        ):\n            import os\n            import dill\n            from mlflow.sklearn import save_model\n\n            from mlflow.tracking.client import MlflowClient\n\n            os.environ["MLFLOW_S3_ENDPOINT_URL"] = "http://minio-service.kubeflow.svc:9000"\n            os.environ["AWS_ACCESS_KEY_ID"] = "minio"\n            os.environ["AWS_SECRET_ACCESS_KEY"] = "minio123"\n\n            client = MlflowClient("http://mlflow-server-service.mlflow-system.svc:5000")\n\n            with open(model_path, mode="rb") as file_reader:\n                clf = dill.load(file_reader)\n\n            with open(input_example_path, "rb") as file_reader:\n                input_example = dill.load(file_reader)\n\n            with open(signature_path, "rb") as file_reader:\n                signature = dill.load(file_reader)\n\n            with open(conda_env_path, "rb") as file_reader:\n                conda_env = dill.load(file_reader)\n\n            save_model(\n                sk_model=clf,\n                path=model_name,\n                serialization_format="cloudpickle",\n                conda_env=conda_env,\n                signature=signature,\n                input_example=input_example,\n            )\n            run = client.create_run(experiment_id="0")\n            client.log_artifact(run.info.run_id, model_name)\n\n        import argparse\n        _parser = argparse.ArgumentParser(prog=\'Upload sklearn model to mlflow\', description=\'\')\n        _parser.add_argument("--model-name", dest="model_name", type=str, required=True, default=argparse.SUPPRESS)\n        _parser.add_argument("--model", dest="model_path", type=str, required=True, default=argparse.SUPPRESS)\n        _parser.add_argument("--input-example", dest="input_example_path", type=str, required=True, default=argparse.SUPPRESS)\n        _parser.add_argument("--signature", dest="signature_path", type=str, required=True, default=argparse.SUPPRESS)\n        _parser.add_argument("--conda-env", dest="conda_env_path", type=str, required=True, default=argparse.SUPPRESS)\n        _parsed_args = vars(_parser.parse_args())\n\n        _outputs = upload_sklearn_model_to_mlflow(**_parsed_args)\n      image: python:3.7\n    inputs:\n      parameters:\n      - {name: model_name}\n      artifacts:\n      - {name: train-from-csv-conda_env, path: /tmp/inputs/conda_env/data}\n      - {name: train-from-csv-input_example, path: /tmp/inputs/input_example/data}\n      - {name: train-from-csv-model, path: /tmp/inputs/model/data}\n      - {name: train-from-csv-signature, path: /tmp/inputs/signature/data}\n    metadata:\n      labels:\n        pipelines.kubeflow.org/kfp_sdk_version: 1.8.10\n        pipelines.kubeflow.org/pipeline-sdk-type: kfp\n        pipelines.kubeflow.org/enable_caching: "true"\n      annotations: {pipelines.kubeflow.org/component_spec: \'{"implementation": {"container":\n          {"args": ["--model-name", {"inputValue": "model_name"}, "--model", {"inputPath":\n          "model"}, "--input-example", {"inputPath": "input_example"}, "--signature",\n          {"inputPath": "signature"}, "--conda-env", {"inputPath": "conda_env"}],\n          "command": ["sh", "-c", "(PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip\n          install --quiet --no-warn-script-location \'\'dill\'\' \'\'pandas\'\' \'\'scikit-learn\'\'\n          \'\'mlflow\'\' \'\'boto3\'\' || PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install\n          --quiet --no-warn-script-location \'\'dill\'\' \'\'pandas\'\' \'\'scikit-learn\'\' \'\'mlflow\'\'\n          \'\'boto3\'\' --user) && \\"$0\\" \\"$@\\"", "sh", "-ec", "program_path=$(mktemp)\\nprintf\n          \\"%s\\" \\"$0\\" > \\"$program_path\\"\\npython3 -u \\"$program_path\\" \\"$@\\"\\n",\n          "def upload_sklearn_model_to_mlflow(\\n    model_name,\\n    model_path,\\n    input_example_path,\\n    signature_path,\\n    conda_env_path,\\n):\\n    import\n          os\\n    import dill\\n    from mlflow.sklearn import save_model\\n\\n    from\n          mlflow.tracking.client import MlflowClient\\n\\n    os.environ[\\"MLFLOW_S3_ENDPOINT_URL\\"]\n          = \\"http://minio-service.kubeflow.svc:9000\\"\\n    os.environ[\\"AWS_ACCESS_KEY_ID\\"]\n          = \\"minio\\"\\n    os.environ[\\"AWS_SECRET_ACCESS_KEY\\"] = \\"minio123\\"\\n\\n    client\n          = MlflowClient(\\"http://mlflow-server-service.mlflow-system.svc:5000\\")\\n\\n    with\n          open(model_path, mode=\\"rb\\") as file_reader:\\n        clf = dill.load(file_reader)\\n\\n    with\n          open(input_example_path, \\"rb\\") as file_reader:\\n        input_example\n          = dill.load(file_reader)\\n\\n    with open(signature_path, \\"rb\\") as file_reader:\\n        signature\n          = dill.load(file_reader)\\n\\n    with open(conda_env_path, \\"rb\\") as file_reader:\\n        conda_env\n          = dill.load(file_reader)\\n\\n    save_model(\\n        sk_model=clf,\\n        path=model_name,\\n        serialization_format=\\"cloudpickle\\",\\n        conda_env=conda_env,\\n        signature=signature,\\n        input_example=input_example,\\n    )\\n    run\n          = client.create_run(experiment_id=\\"0\\")\\n    client.log_artifact(run.info.run_id,\n          model_name)\\n\\nimport argparse\\n_parser = argparse.ArgumentParser(prog=\'\'Upload\n          sklearn model to mlflow\'\', description=\'\'\'\')\\n_parser.add_argument(\\"--model-name\\",\n          dest=\\"model_name\\", type=str, required=True, default=argparse.SUPPRESS)\\n_parser.add_argument(\\"--model\\",\n          dest=\\"model_path\\", type=str, required=True, default=argparse.SUPPRESS)\\n_parser.add_argument(\\"--input-example\\",\n          dest=\\"input_example_path\\", type=str, required=True, default=argparse.SUPPRESS)\\n_parser.add_argument(\\"--signature\\",\n          dest=\\"signature_path\\", type=str, required=True, default=argparse.SUPPRESS)\\n_parser.add_argument(\\"--conda-env\\",\n          dest=\\"conda_env_path\\", type=str, required=True, default=argparse.SUPPRESS)\\n_parsed_args\n          = vars(_parser.parse_args())\\n\\n_outputs = upload_sklearn_model_to_mlflow(**_parsed_args)\\n"],\n          "image": "python:3.7"}}, "inputs": [{"name": "model_name", "type": "String"},\n          {"name": "model", "type": "dill"}, {"name": "input_example", "type": "dill"},\n          {"name": "signature", "type": "dill"}, {"name": "conda_env", "type": "dill"}],\n          "name": "Upload sklearn model to mlflow"}\', pipelines.kubeflow.org/component_ref: \'{}\',\n        pipelines.kubeflow.org/arguments.parameters: \'{"model_name": "{{inputs.parameters.model_name}}"}\'}\n  arguments:\n    parameters:\n    - {name: kernel}\n    - {name: model_name}\n  serviceAccountName: pipeline-runner\n')))),(0,r.kt)("p",null,"\uc2e4\ud589\ud6c4 \uc0dd\uc131\ub41c mlflow_pipeline.yaml \ud30c\uc77c\uc744 \ud30c\uc774\ud504\ub77c\uc778 \uc5c5\ub85c\ub4dc\ud55c \ud6c4, \uc2e4\ud589\ud558\uc5ec run \uc758 \uacb0\uacfc\ub97c \ud655\uc778\ud569\ub2c8\ub2e4."),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"mlflow-svc-0",src:a(1822).Z,width:"3408",height:"2156"})),(0,r.kt)("p",null,"mlflow service\ub97c \ud3ec\ud2b8\ud3ec\uc6cc\ub529\ud574\uc11c MLflow ui\uc5d0 \uc811\uc18d\ud569\ub2c8\ub2e4."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl port-forward svc/mlflow-server-service -n mlflow-system 5000:5000\n")),(0,r.kt)("p",null,"\uc6f9 \ube0c\ub77c\uc6b0\uc800\ub97c \uc5f4\uc5b4 localhost:5000\uc73c\ub85c \uc811\uc18d\ud558\uba74, \ub2e4\uc74c\uacfc \uac19\uc774 run\uc774 \uc0dd\uc131\ub41c \uac83\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4."),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"mlflow-svc-1",src:a(339).Z,width:"3360",height:"2100"})),(0,r.kt)("p",null,"run \uc744 \ud074\ub9ad\ud574\uc11c \ud655\uc778\ud558\uba74 \ud559\uc2b5\ud55c \ubaa8\ub378 \ud30c\uc77c\uc774 \uc788\ub294 \uac83\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4."),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"mlflow-svc-2",src:a(7463).Z,width:"3360",height:"2100"})))}_.isMDXComponent=!0},3810:(n,e,a)=>{a.d(e,{Z:()=>t});const t=a.p+"assets/images/mlflow-0-95d5ec759ef43b21c9c3b22abb64366d.png"},8705:(n,e,a)=>{a.d(e,{Z:()=>t});const t=a.p+"assets/images/mlflow-1-a096f3eda2246a1c132fc13ce3180ef5.png"},9481:(n,e,a)=>{a.d(e,{Z:()=>t});const t=a.p+"assets/images/mlflow-2-3cd7cf7e2c853a1242cff7c65e56cf3f.png"},3268:(n,e,a)=>{a.d(e,{Z:()=>t});const t=a.p+"assets/images/mlflow-3-8b187057bb18f27b1744656ef6d045a1.png"},1822:(n,e,a)=>{a.d(e,{Z:()=>t});const t=a.p+"assets/images/mlflow-svc-0-ab6c5d7f00bf643c36d236155dc5eb9c.png"},339:(n,e,a)=>{a.d(e,{Z:()=>t});const t=a.p+"assets/images/mlflow-svc-1-7723b8f92fb8cea2ff99b8f4639ff0c6.png"},7463:(n,e,a)=>{a.d(e,{Z:()=>t});const t=a.p+"assets/images/mlflow-svc-2-8b696bd65a922f949877102bbfdafc42.png"}}]);